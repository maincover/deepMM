{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detectron\n",
    "\n",
    "## Region Proposals\n",
    "we expect the proposals for a dataset to be provided in a pkl file that contains a serialized proposals dictionary with the following entries:\n",
    "\n",
    "proposals.keys() - ['cfg', 'ids', 'scores', 'boxes']\n",
    "\n",
    "where\n",
    "\n",
    "proposals['cfg'] - config used to compute the proposals\n",
    "\n",
    "proposals['ids][i] - id for the i-th image\n",
    "\n",
    "proposals['scores'][i] - ndarray (N_i,) containing scores for the proposals in the i-th image\n",
    "\n",
    "proposals['boxes'][i]  - ndarray (N_i, 4) containing coordinates (x1, y1, x2, y2) for the proposals in the i-th image\n",
    "\n",
    "\n",
    "It may be instructive to download one of the proposal files from the Model Zoo and inspect it interactively. You may also find it useful to look at [_add_proposals_from_file](https://github.com/facebookresearch/Detectron/blob/master/detectron/datasets/json_dataset.py#L248) to see how proposals get loaded from file and [rpn_generator](https://github.com/facebookresearch/Detectron/blob/master/detectron/core/rpn_generator.py) to see how RPN proposals get computed and stored to a pkl file.\n",
    "\n",
    "If you require proposals for COCO classes, you can use one of the RPN models from the Model Zoo to compute (and store in the expected format) the proposals for your dataset.\n",
    "\n",
    "We plan to add the information about the proposals file format to the documentation in the future.\n",
    "In the meantime, let us know if the above is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Trainning process](./20180517211835738.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Training](./20180517211851218.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Blobs，Workspace，Tensors\n",
    "\n",
    "Caffe2 的 Data 是以 blobs 的形式组织的.\n",
    "\n",
    "blob 即是内存中被命名的 data chunk(数据块).\n",
    "\n",
    "blobs 一般包含一个 tensor(可以看做是多维数组)，在 Python 中的存在形式是 numpy arrays.\n",
    "\n",
    "Workspace 存储所有的 blobs. 如下例，展示了将 blobs 送入 workspace (Feed) 以及从 workspace 读取 blobs [Fetch]的方法.\n",
    "\n",
    "Workspaces 在开始使用时会自动初始化."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.43033336 0.07997708]\n",
      "  [0.23825377 0.54042483]\n",
      "  [0.0034584  0.66832894]]\n",
      "\n",
      " [[0.80541561 0.53480687]\n",
      "  [0.66886001 0.25899185]\n",
      "  [0.34194229 0.22800033]]\n",
      "\n",
      " [[0.32670712 0.64598489]\n",
      "  [0.1278269  0.39553063]\n",
      "  [0.11457012 0.63205072]]\n",
      "\n",
      " [[0.98938501 0.5224455 ]\n",
      "  [0.34141606 0.41883644]\n",
      "  [0.45854937 0.15138438]]]\n",
      "(4, 3, 2)\n",
      "[[[0.43033336 0.07997708]\n",
      "  [0.23825377 0.54042483]\n",
      "  [0.0034584  0.66832894]]\n",
      "\n",
      " [[0.80541561 0.53480687]\n",
      "  [0.66886001 0.25899185]\n",
      "  [0.34194229 0.22800033]]\n",
      "\n",
      " [[0.32670712 0.64598489]\n",
      "  [0.1278269  0.39553063]\n",
      "  [0.11457012 0.63205072]]\n",
      "\n",
      " [[0.98938501 0.5224455 ]\n",
      "  [0.34141606 0.41883644]\n",
      "  [0.45854937 0.15138438]]]\n"
     ]
    }
   ],
   "source": [
    "from caffe2.python import workspace, model_helper\n",
    "import numpy as np\n",
    "# Create random tensor of three dimensions\n",
    "x = np.random.rand(4, 3, 2)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "workspace.FeedBlob(\"my_x\", x)\n",
    "\n",
    "x2 = workspace.FetchBlob(\"my_x\")\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Nets，Operators\n",
    "\n",
    "Caffe2 基础的模型抽象是 net.\n",
    "\n",
    "net 是由 operators 组成的 graph，每一个 operator 根据输入 input blobs 集，而输出一个或多个 output blobs.\n",
    "\n",
    "以构建简单网络模型为例，其包括以下几种组成：\n",
    "\n",
    ">    1 个全连接层(FC)；\n",
    "\n",
    ">    1 个采用 softmax 的 Sigmoid 激活层；\n",
    "\n",
    ">    1 个 CrossEntropy 层\n",
    "\n",
    "这里不直接构建 nets，而是借助 model_helpers 来进行 nets 构建； model_helpers 是创建 nets 的 Python 类.\n",
    "\n",
    "将待创建的网络记为 “my first net”，ModelHelper 会另外创建两个相互关联的 nets：\n",
    "\n",
    "+ 一个是，参数初始化网络(记 init_net)\n",
    "+ 一个是，真实训练网络(记 exec_net)\n",
    "\n",
    "首先，随机生成 data 和label，并作为 blobs 输入到 workspace：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 0 8 9 4 8 9 3 1 3 5 1 1 6 6]\n"
     ]
    }
   ],
   "source": [
    "# Create the input data\n",
    "data = np.random.rand(16, 100).astype(np.float32)\n",
    "\n",
    "# Create labels for the data as integers [0, 9]\n",
    "label = (np.random.rand(16) * 10).astype(np.int32)\n",
    "\n",
    "workspace.FeedBlob(\"data\", data)\n",
    "workspace.FeedBlob(\"label\", label)\n",
    "\n",
    "print label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，采用 model_helper 来创建 init_net 和 exec_net；并接着对 model 采用 FC operator 添加全连接层. 这里 FC op 需要先生成一些随机 fills.\n",
    "\n",
    "生成随机 fills 后，即可将 fc ops 添加到模型，并使用创建的 weights 和 bias blobs，可以根据其名字进行调用.\n",
    "\n",
    "Caffe2 中，FC op 包括三部分： input blob，weights 和 bias. Weights 和 bias 可以使用 XavierFill 或 ConstantFill初始化，参数包括三部分： [ ] - 空数组；’fc_w/fc_b’ - 名称；shape - shape=[output, input]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using a model helper\n",
    "m = model_helper.ModelHelper(name=\"my first net\")\n",
    "\n",
    "# Create random fills\n",
    "weight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])\n",
    "bias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])\n",
    "\n",
    "fc_1 = m.net.FC([\"data\", \"fc_w\", \"fc_b\"], \"fc1\")\n",
    "pred = m.net.Sigmoid(fc_1, \"pred\")\n",
    "softmax, loss = m.net.SoftmaxWithLoss([pred, \"label\"], [\"softmax\", \"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顾下创建过程：\n",
    "\n",
    "*        首先，创建内存里的 input data 和 label blobs；实际应用中，从相应的 database 来加载读取.\n",
    "\n",
    "*        data 和 label blobs 的 first dim=16，即 batchsize=16.\n",
    "\n",
    "        >基于 ModelHelper 可以进行处理许多 Caffe2 operators，更多细节参考 ModelHelper’s Operator List.\n",
    "\n",
    "        >然后，通过定义多个 operators 来创建模型：FC, Sigmoid 和 SoftmaxWithLoss.\n",
    "\n",
    "        >此时，只是定义了 operators 和 model.\n",
    "\n",
    "        >ModelHelper 创建了两个 nets：\n",
    "*            m.param_init_net\n",
    "\n",
    "        > 只运行一次；初始化参数 blobs；\n",
    "*            m.net \n",
    "\n",
    "        > 训练网络.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络定义保存为 protobuf 结构，可以通过调用 net.Proto() 来查看网络结构."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"my first net\"\n",
      "op {\n",
      "  input: \"data\"\n",
      "  input: \"fc_w\"\n",
      "  input: \"fc_b\"\n",
      "  output: \"fc1\"\n",
      "  name: \"\"\n",
      "  type: \"FC\"\n",
      "}\n",
      "op {\n",
      "  input: \"fc1\"\n",
      "  output: \"pred\"\n",
      "  name: \"\"\n",
      "  type: \"Sigmoid\"\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"label\"\n",
      "  output: \"softmax\"\n",
      "  output: \"loss\"\n",
      "  name: \"\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "}\n",
      "external_input: \"data\"\n",
      "external_input: \"fc_w\"\n",
      "external_input: \"fc_b\"\n",
      "external_input: \"label\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.net.Proto())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数初始化化网络："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(m.param_init_net.Proto())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Executing\n",
    "\n",
    "定义好模型训练 operators 后，可以开始训练模型.\n",
    "\n",
    "首先，运行一次参数初始化网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.RunNetOnce(m.param_init_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，创建训练网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.CreateNet(m.net)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接着，网络训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 x 10 iterations\n",
    "for _ in range(100):\n",
    "    data = np.random.rand(16, 100).astype(np.float32)\n",
    "    label = (np.random.rand(16) * 10).astype(np.int32)\n",
    "\n",
    "    workspace.FeedBlob(\"data\", data)\n",
    "    workspace.FeedBlob(\"label\", label)\n",
    "\n",
    "    workspace.RunNet(m.name, 10)   # run for 10 times\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 output blobs 中存储的结果(tensor 或 numpy arrays)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0996676  0.106478   0.09701066 0.08899877 0.09087525 0.12313581\n",
      "  0.08970322 0.09767637 0.07804448 0.12840985]\n",
      " [0.10409921 0.09452977 0.10418763 0.09370263 0.0992988  0.10074376\n",
      "  0.10542777 0.09532675 0.07690793 0.1257758 ]\n",
      " [0.10008782 0.1073982  0.10511231 0.09442125 0.1003889  0.10805362\n",
      "  0.0882118  0.10012326 0.08153807 0.11466472]\n",
      " [0.10086697 0.09680157 0.10652861 0.09293644 0.09050947 0.12851849\n",
      "  0.08417885 0.09827408 0.08465172 0.11673386]\n",
      " [0.10552079 0.10716329 0.10421419 0.09145997 0.09182318 0.10571703\n",
      "  0.09837991 0.09556746 0.08923232 0.11092188]\n",
      " [0.09554937 0.09340698 0.0980005  0.09848753 0.10364331 0.11400795\n",
      "  0.08586583 0.09842174 0.08205641 0.13056038]\n",
      " [0.10202828 0.10348208 0.09235468 0.09227832 0.10147054 0.11293191\n",
      "  0.09366265 0.10828981 0.08411993 0.10938174]\n",
      " [0.10461167 0.08678544 0.09262975 0.11165063 0.10635261 0.10574176\n",
      "  0.07946953 0.10056494 0.08504988 0.12714386]\n",
      " [0.11275623 0.09755217 0.09503955 0.09639841 0.09836872 0.11127587\n",
      "  0.09125371 0.09013569 0.07739443 0.1298253 ]\n",
      " [0.10410105 0.09515922 0.10941165 0.08679865 0.10154111 0.11708576\n",
      "  0.08418909 0.10613707 0.06930783 0.12626858]\n",
      " [0.10791343 0.10615302 0.09549616 0.08476615 0.09730446 0.11806374\n",
      "  0.09570929 0.09699833 0.08218342 0.11541197]\n",
      " [0.10521095 0.1017776  0.0932415  0.08564296 0.09764459 0.11944718\n",
      "  0.08386785 0.09894061 0.07983206 0.13439468]\n",
      " [0.09994696 0.09875556 0.10644736 0.0954819  0.10945144 0.11211891\n",
      "  0.09474629 0.09109019 0.08662633 0.10533509]\n",
      " [0.10870804 0.10037629 0.10549184 0.09474152 0.08526056 0.11130846\n",
      "  0.09250276 0.11338224 0.08473368 0.10349461]\n",
      " [0.09178621 0.09969992 0.09364329 0.09404939 0.10855945 0.11778163\n",
      "  0.09617525 0.10513771 0.07342662 0.11974061]\n",
      " [0.10919163 0.10493183 0.09436467 0.0959816  0.11038062 0.10109758\n",
      "  0.09180047 0.10712273 0.0792983  0.10583054]]\n",
      "2.3301048\n"
     ]
    }
   ],
   "source": [
    "print(workspace.FetchBlob(\"softmax\"))\n",
    "print(workspace.FetchBlob(\"loss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Backward pass\n",
    "\n",
    "以上网络训练只有 forward pass，没有学习.\n",
    "\n",
    "通过对 forward pass 中的每个 operator 创建其梯度 operators，即可 backward pass.\n",
    "\n",
    "如果已经根据规范进行尝试，可以采用以下处理来检查结果.\n",
    "\n",
    "*    调用 RunNetOnce 前，插入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{BlobReference(\"data\"): BlobReference(\"data_grad\"),\n",
       " BlobReference(\"fc_w\"): BlobReference(\"fc_w_grad\"),\n",
       " BlobReference(\"pred\"): BlobReference(\"pred_grad\"),\n",
       " BlobReference(\"loss\"): BlobReference(\"loss_autogen_grad\"),\n",
       " BlobReference(\"fc_b\"): BlobReference(\"fc_b_grad\"),\n",
       " BlobReference(\"fc1\"): BlobReference(\"fc1_grad\")}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.AddGradientOperators([loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 检查 protobuf 输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"my first net\"\n",
      "op {\n",
      "  input: \"data\"\n",
      "  input: \"fc_w\"\n",
      "  input: \"fc_b\"\n",
      "  output: \"fc1\"\n",
      "  name: \"\"\n",
      "  type: \"FC\"\n",
      "}\n",
      "op {\n",
      "  input: \"fc1\"\n",
      "  output: \"pred\"\n",
      "  name: \"\"\n",
      "  type: \"Sigmoid\"\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"label\"\n",
      "  output: \"softmax\"\n",
      "  output: \"loss\"\n",
      "  name: \"\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "}\n",
      "op {\n",
      "  input: \"loss\"\n",
      "  output: \"loss_autogen_grad\"\n",
      "  name: \"\"\n",
      "  type: \"ConstantFill\"\n",
      "  arg {\n",
      "    name: \"value\"\n",
      "    f: 1.0\n",
      "  }\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"label\"\n",
      "  input: \"softmax\"\n",
      "  input: \"loss_autogen_grad\"\n",
      "  output: \"pred_grad\"\n",
      "  name: \"\"\n",
      "  type: \"SoftmaxWithLossGradient\"\n",
      "  is_gradient_op: true\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"pred_grad\"\n",
      "  output: \"fc1_grad\"\n",
      "  name: \"\"\n",
      "  type: \"SigmoidGradient\"\n",
      "  is_gradient_op: true\n",
      "}\n",
      "op {\n",
      "  input: \"data\"\n",
      "  input: \"fc_w\"\n",
      "  input: \"fc1_grad\"\n",
      "  output: \"fc_w_grad\"\n",
      "  output: \"fc_b_grad\"\n",
      "  output: \"data_grad\"\n",
      "  name: \"\"\n",
      "  type: \"FCGradient\"\n",
      "  is_gradient_op: true\n",
      "}\n",
      "external_input: \"data\"\n",
      "external_input: \"fc_w\"\n",
      "external_input: \"fc_b\"\n",
      "external_input: \"label\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.net.Proto())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
